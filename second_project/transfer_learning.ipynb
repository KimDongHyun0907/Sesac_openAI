{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet18  \n",
    "fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7219103872776031\n",
      "Epoch [2/10], Loss: 0.2060864269733429\n",
      "Epoch [3/10], Loss: 0.03430333733558655\n",
      "Epoch [4/10], Loss: 0.006679045967757702\n",
      "Epoch [5/10], Loss: 0.0017442298703826964\n",
      "Epoch [6/10], Loss: 0.000585255867918022\n",
      "Epoch [7/10], Loss: 0.0002408322543487884\n",
      "Epoch [8/10], Loss: 0.00011699690003297292\n",
      "Epoch [9/10], Loss: 6.526492143166251e-05\n",
      "Epoch [10/10], Loss: 4.070913382747676e-05\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 크기에 맞는 CNN 모델 불러오기 (예: ResNet18)\n",
    "model1 = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모델의 마지막 레이어를 새로운 fully connected layer로 교체\n",
    "num_features = model1.fc.in_features\n",
    "model1.fc = nn.Linear(num_features, 2)  # 예시에서는 클래스가 2개라 가정\n",
    "\n",
    "# GPU 사용이 가능하다면 GPU로 모델 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = model1.to(device)\n",
    "\n",
    "# Loss function 및 optimizer 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 학습 데이터 및 레이블\n",
    "xTrainName = \"xTrain.pkl\"\n",
    "yTrainName = \"yTrain.pkl\"\n",
    "\n",
    "with open(xTrainName,'rb') as f1:\n",
    "    X = pickle.load(f1)\n",
    "\n",
    "with open(yTrainName,'rb') as f2:\n",
    "    y = pickle.load(f2)\n",
    "\n",
    "x_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "# 데이터를 PyTorch 텐서로 변환\n",
    "x_train = torch.tensor(np.tile(x_np, (2, 1, 1, 1)), dtype=torch.float32)  # 배치 차원 추가하여 [배치 크기, 채널 수(여기서는 1), 높이, 너비]\n",
    "x_train = x_train.expand(-1, 3, -1, -1)  # 1개의 채널을 3개의 채널로 확장\n",
    "y_train = torch.tensor(np.tile(y_np, (2,)), dtype=torch.long)  # 배치 차원 추가하지 않음\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model1.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in zip(x_train, y_train):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "        outputs = model1(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(0).to(device))  # 배치 차원 추가\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(x_train)}\")\n",
    "\n",
    "print(\"학습 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 모델을 evaluation 모드로 설정\n",
    "model1.eval()\n",
    "\n",
    "# 모델이 예측한 결과와 실제 레이블을 비교하여 정확도 계산\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in zip(x_train, y_train):\n",
    "        inputs = inputs.unsqueeze(0).to(device)\n",
    "        outputs = model1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += 1\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet18  \n",
    "1d conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5772333741188049\n",
      "Epoch [2/10], Loss: 0.3981121927499771\n",
      "Epoch [3/10], Loss: 0.21757658571004868\n",
      "Epoch [4/10], Loss: 0.1055511012673378\n",
      "Epoch [5/10], Loss: 0.048364829272031784\n",
      "Epoch [6/10], Loss: 0.022694178856909275\n",
      "Epoch [7/10], Loss: 0.011362233199179173\n",
      "Epoch [8/10], Loss: 0.006183403776958585\n",
      "Epoch [9/10], Loss: 0.0036628663074225187\n",
      "Epoch [10/10], Loss: 0.0023467119317501783\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 크기에 맞는 CNN 모델 불러오기 (예: ResNet18)\n",
    "model2 = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모델의 마지막 레이어를 변경하고자 할 경우\n",
    "# 모델의 마지막 레이어 이전의 출력 차원을 확인\n",
    "num_features = model2.fc.in_features\n",
    "\n",
    "# 새로운 모델 정의\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.features = nn.Sequential(*list(model2.children())[:-2])  # ResNet의 마지막 2개 레이어 제외\n",
    "        self.conv1d = nn.Conv1d(num_features, 64, kernel_size=3, stride=1, padding=1)  # 1D Convolutional Layer 추가\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(64, 2)  # 예시에서는 클래스가 2개라 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), num_features, -1)  # Flatten 작업\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)  # 1D로 평탄화\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 새로운 모델 생성\n",
    "model2 = CustomModel(num_features)\n",
    "\n",
    "# GPU 사용이 가능하다면 GPU로 모델 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model2 = model2.to(device)\n",
    "\n",
    "# Loss function 및 optimizer 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 학습 데이터 및 레이블\n",
    "xTrainName = \"xTrain.pkl\"\n",
    "yTrainName = \"yTrain.pkl\"\n",
    "\n",
    "with open(xTrainName,'rb') as f1:\n",
    "    X = pickle.load(f1)\n",
    "\n",
    "with open(yTrainName,'rb') as f2:\n",
    "    y = pickle.load(f2)\n",
    "\n",
    "x_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "# 데이터를 PyTorch 텐서로 변환\n",
    "x_train = torch.tensor(np.tile(x_np, (2, 1, 1, 1)), dtype=torch.float32)  # 배치 차원 추가하여 [배치 크기, 채널 수(여기서는 1), 높이, 너비]\n",
    "x_train = x_train.expand(-1, 3, -1, -1)  # 1개의 채널을 3개의 채널로 확장\n",
    "y_train = torch.tensor(np.tile(y_np, (2,)), dtype=torch.long)  # 배치 차원 추가하지 않음\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in zip(x_train, y_train):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(0).to(device))  # 배치 차원 추가\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(x_train)}\")\n",
    "\n",
    "print(\"학습 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 모델을 evaluation 모드로 설정\n",
    "model2.eval()\n",
    "\n",
    "# 모델이 예측한 결과와 실제 레이블을 비교하여 정확도 계산\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in zip(x_train, y_train):\n",
    "        inputs = inputs.unsqueeze(0).to(device)\n",
    "        outputs = model2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += 1\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet18  \n",
    "2d conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5847071707248688\n",
      "Epoch [2/10], Loss: 0.37857693433761597\n",
      "Epoch [3/10], Loss: 0.17081908881664276\n",
      "Epoch [4/10], Loss: 0.06395904161036015\n",
      "Epoch [5/10], Loss: 0.023804597556591034\n",
      "Epoch [6/10], Loss: 0.009719994850456715\n",
      "Epoch [7/10], Loss: 0.004481855663470924\n",
      "Epoch [8/10], Loss: 0.002331458032131195\n",
      "Epoch [9/10], Loss: 0.0013498947373591363\n",
      "Epoch [10/10], Loss: 0.0008576967229600996\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 크기에 맞는 CNN 모델 불러오기 (예: ResNet18)\n",
    "model3 = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모델의 마지막 레이어를 변경하고자 할 경우\n",
    "# 모델의 마지막 레이어 이전의 출력 차원을 확인\n",
    "num_features = model3.fc.in_features\n",
    "\n",
    "# 새로운 모델 정의\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.features = nn.Sequential(*list(model3.children())[:-2])  # ResNet의 마지막 2개 레이어 제외\n",
    "        self.conv2d = nn.Conv2d(num_features, 64, kernel_size=3, stride=1, padding=1)  # 2D Convolutional Layer 추가\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, 2)  # 예시에서는 클래스가 2개라 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv2d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)  # 2D 출력을 1D로 평탄화\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 새로운 모델 생성\n",
    "model3 = CustomModel(num_features)\n",
    "\n",
    "# GPU 사용이 가능하다면 GPU로 모델 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model3 = model3.to(device)\n",
    "\n",
    "# Loss function 및 optimizer 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model3.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 학습 데이터 및 레이블\n",
    "xTrainName = \"xTrain.pkl\"\n",
    "yTrainName = \"yTrain.pkl\"\n",
    "\n",
    "with open(xTrainName,'rb') as f1:\n",
    "    X = pickle.load(f1)\n",
    "\n",
    "with open(yTrainName,'rb') as f2:\n",
    "    y = pickle.load(f2)\n",
    "\n",
    "x_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "# 데이터를 PyTorch 텐서로 변환\n",
    "x_train = torch.tensor(np.tile(x_np, (2, 1, 1, 1)), dtype=torch.float32)  # 배치 차원 추가하여 [배치 크기, 채널 수(여기서는 1), 높이, 너비]\n",
    "x_train = x_train.expand(-1, 3, -1, -1)  # 1개의 채널을 3개의 채널로 확장\n",
    "y_train = torch.tensor(np.tile(y_np, (2,)), dtype=torch.long)  # 배치 차원 추가하지 않음\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model3.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in zip(x_train, y_train):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "        outputs = model3(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(0).to(device))  # 배치 차원 추가\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(x_train)}\")\n",
    "\n",
    "print(\"학습 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 모델을 evaluation 모드로 설정\n",
    "model3.eval()\n",
    "\n",
    "# 모델이 예측한 결과와 실제 레이블을 비교하여 정확도 계산\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in zip(x_train, y_train):\n",
    "        inputs = inputs.unsqueeze(0).to(device)\n",
    "        outputs = model3(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += 1\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

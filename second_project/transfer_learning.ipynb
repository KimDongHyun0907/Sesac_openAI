{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet18  \n",
    "fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 크기에 맞는 CNN 모델 불러오기 (예: ResNet18)\n",
    "model1 = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모델의 마지막 레이어를 새로운 fully connected layer로 교체\n",
    "num_features = model1.fc.in_features\n",
    "model1.fc = nn.Linear(num_features, 2)  # 예시에서는 클래스가 2개라 가정\n",
    "\n",
    "# GPU 사용이 가능하다면 GPU로 모델 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = model1.to(device)\n",
    "\n",
    "# Loss function 및 optimizer 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 학습 데이터 및 레이블\n",
    "xTrainName = \"xTrain.pkl\"\n",
    "yTrainName = \"yTrain.pkl\"\n",
    "\n",
    "with open(xTrainName,'rb') as f1:\n",
    "    X = pickle.load(f1)\n",
    "\n",
    "with open(yTrainName,'rb') as f2:\n",
    "    y = pickle.load(f2)\n",
    "\n",
    "x_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_np, y_np, test_size= 0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200, 800)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_tensor(data):\n",
    "    np_test_tensor = []\n",
    "    for i in data:\n",
    "        np_test = np.tile(i, (1,4))\n",
    "        np_test = np.tile(np_test, (28,1))\n",
    "        np_test = torch.tensor(np_test, dtype=torch.float32)\n",
    "        np_test = np_test.expand(3,-1,-1)\n",
    "\n",
    "        np_test_tensor.append(np_test)\n",
    "\n",
    "    np_test_tensor = np.array(np_test_tensor)\n",
    "    np_test_tensor = torch.tensor(np_test_tensor)\n",
    "    return np_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = change_tensor(x_train)\n",
    "x_test = change_tensor(x_test)\n",
    "y_train = torch.tensor(np.tile(y_train, (1,)), dtype=torch.long)\n",
    "y_test = torch.tensor(np.tile(y_test, (1,)), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7200, 3, 28, 28])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data\n",
    "        label = self.labels\n",
    "            \n",
    "        return data[idx], label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.006942493869638485\n",
      "Epoch [2/10], Loss: 0.003655602261165364\n",
      "Epoch [3/10], Loss: 0.002698197704093117\n",
      "Epoch [4/10], Loss: 0.002555801309709851\n",
      "Epoch [5/10], Loss: 0.001990881750955143\n",
      "Epoch [6/10], Loss: 0.0016875280388113526\n",
      "Epoch [7/10], Loss: 0.0016304093971848488\n",
      "Epoch [8/10], Loss: 0.00172927631809014\n",
      "Epoch [9/10], Loss: 0.001512985364372273\n",
      "Epoch [10/10], Loss: 0.0013260644622399317\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model1.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)  # 배치 차원 추가\n",
    "        outputs = model1(inputs)\n",
    "        loss = criterion(outputs, labels.to(device))  # 배치 차원 추가\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(x_train)}\")\n",
    "\n",
    "print(\"학습 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n",
      "Accuracy: 97.0000%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 모델을 evaluation 모드로 설정\n",
    "model1.eval()\n",
    "\n",
    "# 모델이 예측한 결과와 실제 레이블을 비교하여 정확도 계산\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in zip(x_test, y_test):\n",
    "        inputs = inputs.unsqueeze(0).to(device)\n",
    "        outputs = model1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += 1\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(accuracy)\n",
    "print(f\"Accuracy: {accuracy * 100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet18  \n",
    "1d conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bluecom014\\miniconda3\\envs\\sesac\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.008073243932125882\n",
      "Epoch [2/10], Loss: 0.003722975878044963\n",
      "Epoch [3/10], Loss: 0.0027511982281511237\n",
      "Epoch [4/10], Loss: 0.0027145783400111313\n",
      "Epoch [5/10], Loss: 0.0020111356867710127\n",
      "Epoch [6/10], Loss: 0.0019502820013116838\n",
      "Epoch [7/10], Loss: 0.0018316858849074277\n",
      "Epoch [8/10], Loss: 0.0015834826717683527\n",
      "Epoch [9/10], Loss: 0.0014597541671052265\n",
      "Epoch [10/10], Loss: 0.0014379769831430167\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def change_tensor(data):\n",
    "    np_test_tensor = []\n",
    "    for i in data:\n",
    "        np_test = np.tile(i, (1,4))\n",
    "        np_test = np.tile(np_test, (28,1))\n",
    "        np_test = torch.tensor(np_test, dtype=torch.float32)\n",
    "        np_test = np_test.expand(3,-1,-1)\n",
    "\n",
    "        np_test_tensor.append(np_test)\n",
    "\n",
    "    np_test_tensor = np.array(np_test_tensor)\n",
    "    np_test_tensor = torch.tensor(np_test_tensor)\n",
    "    return np_test_tensor\n",
    "\n",
    "# 데이터셋 크기에 맞는 CNN 모델 불러오기 (예: ResNet18)\n",
    "model2 = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모델의 마지막 레이어를 변경하고자 할 경우\n",
    "# 모델의 마지막 레이어 이전의 출력 차원을 확인\n",
    "num_features = model2.fc.in_features\n",
    "\n",
    "# 새로운 모델 정의\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.features = nn.Sequential(*list(model2.children())[:-2])  # ResNet의 마지막 2개 레이어 제외\n",
    "        self.conv1d = nn.Conv1d(num_features, 64, kernel_size=3, stride=1, padding=1)  # 1D Convolutional Layer 추가\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(64, 2)  # 예시에서는 클래스가 2개라 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), num_features, -1)  # Flatten 작업\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)  # 1D로 평탄화\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 새로운 모델 생성\n",
    "model2 = CustomModel(num_features)\n",
    "\n",
    "# GPU 사용이 가능하다면 GPU로 모델 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model2 = model2.to(device)\n",
    "\n",
    "# Loss function 및 optimizer 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 학습 데이터 및 레이블\n",
    "xTrainName = \"xTrain.pkl\"\n",
    "yTrainName = \"yTrain.pkl\"\n",
    "\n",
    "with open(xTrainName,'rb') as f1:\n",
    "    X = pickle.load(f1)\n",
    "\n",
    "with open(yTrainName,'rb') as f2:\n",
    "    y = pickle.load(f2)\n",
    "\n",
    "x_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_np, y_np, test_size= 0.1, shuffle=True)\n",
    "\n",
    "x_train = change_tensor(x_train)\n",
    "x_test = change_tensor(x_test)\n",
    "y_train = torch.tensor(np.tile(y_train, (1,)), dtype=torch.long)\n",
    "y_test = torch.tensor(np.tile(y_test, (1,)), dtype=torch.long)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data\n",
    "        label = self.labels\n",
    "            \n",
    "        return data[idx], label[idx]\n",
    "\n",
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)  # 배치 차원 추가\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels.to(device))  # 배치 차원 추가\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(x_train)}\")\n",
    "\n",
    "print(\"학습 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 모델을 evaluation 모드로 설정\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 모델이 예측한 결과와 실제 레이블을 비교하여 정확도 계산\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 모델을 evaluation 모드로 설정\n",
    "model2.eval()\n",
    "\n",
    "# 모델이 예측한 결과와 실제 레이블을 비교하여 정확도 계산\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in zip(x_test, y_test):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(accuracy)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet18  \n",
    "2d conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def change_tensor(data):\n",
    "    np_test_tensor = []\n",
    "    for i in data:\n",
    "        np_test = np.tile(i, (1,4))\n",
    "        np_test = np.tile(np_test, (28,1))\n",
    "        np_test = torch.tensor(np_test, dtype=torch.float32)\n",
    "        np_test = np_test.expand(3,-1,-1)\n",
    "\n",
    "        np_test_tensor.append(np_test)\n",
    "\n",
    "    np_test_tensor = np.array(np_test_tensor)\n",
    "    np_test_tensor = torch.tensor(np_test_tensor)\n",
    "    return np_test_tensor\n",
    "\n",
    "# 데이터셋 크기에 맞는 CNN 모델 불러오기 (예: ResNet18)\n",
    "model3 = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모델의 마지막 레이어를 변경하고자 할 경우\n",
    "# 모델의 마지막 레이어 이전의 출력 차원을 확인\n",
    "num_features = model3.fc.in_features\n",
    "\n",
    "# 새로운 모델 정의\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.features = nn.Sequential(*list(model3.children())[:-2])  # ResNet의 마지막 2개 레이어 제외\n",
    "        self.conv2d = nn.Conv2d(num_features, 64, kernel_size=3, stride=1, padding=1)  # 1D Convolutional Layer 추가\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(64, 2)  # 예시에서는 클래스가 2개라 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv2d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)  # 2D 출력을 1D로 평탄화\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 새로운 모델 생성\n",
    "model3 = CustomModel(num_features)\n",
    "\n",
    "# GPU 사용이 가능하다면 GPU로 모델 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model3 = model3.to(device)\n",
    "\n",
    "# Loss function 및 optimizer 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model3.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 학습 데이터 및 레이블\n",
    "xTrainName = \"xTrain.pkl\"\n",
    "yTrainName = \"yTrain.pkl\"\n",
    "\n",
    "with open(xTrainName,'rb') as f1:\n",
    "    X = pickle.load(f1)\n",
    "\n",
    "with open(yTrainName,'rb') as f2:\n",
    "    y = pickle.load(f2)\n",
    "\n",
    "x_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_np, y_np, test_size= 0.1, shuffle=True)\n",
    "\n",
    "x_train = change_tensor(x_train)\n",
    "x_test = change_tensor(x_test)\n",
    "y_train = torch.tensor(np.tile(y_train, (1,)), dtype=torch.long)\n",
    "y_test = torch.tensor(np.tile(y_test, (1,)), dtype=torch.long)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data\n",
    "        label = self.labels\n",
    "            \n",
    "        return data[idx], label[idx]\n",
    "\n",
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model3.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)  # 배치 차원 추가\n",
    "        outputs = model3(inputs)\n",
    "        loss = criterion(outputs, labels.to(device))  # 배치 차원 추가\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(x_train)}\")\n",
    "\n",
    "print(\"학습 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 모델을 evaluation 모드로 설정\n",
    "model3.eval()\n",
    "\n",
    "# 모델이 예측한 결과와 실제 레이블을 비교하여 정확도 계산\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in zip(x_train, y_train):\n",
    "        inputs = inputs.unsqueeze(0).to(device)\n",
    "        outputs = model3(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += 1\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 학습 데이터 및 레이블\n",
    "xTrainName = \"xTrain.pkl\"\n",
    "yTrainName = \"yTrain.pkl\"\n",
    "\n",
    "with open(xTrainName,'rb') as f1:\n",
    "    X = pickle.load(f1)\n",
    "\n",
    "with open(yTrainName,'rb') as f2:\n",
    "    y = pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Softness</th>\n",
       "      <th>HarvestTime</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.924968</td>\n",
       "      <td>0.468078</td>\n",
       "      <td>3.077832</td>\n",
       "      <td>-1.472177</td>\n",
       "      <td>0.294799</td>\n",
       "      <td>2.435570</td>\n",
       "      <td>0.271290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.409751</td>\n",
       "      <td>0.486870</td>\n",
       "      <td>0.346921</td>\n",
       "      <td>-2.495099</td>\n",
       "      <td>-0.892213</td>\n",
       "      <td>2.067549</td>\n",
       "      <td>0.307325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.357607</td>\n",
       "      <td>1.483176</td>\n",
       "      <td>1.568452</td>\n",
       "      <td>-2.645145</td>\n",
       "      <td>-0.647267</td>\n",
       "      <td>3.090643</td>\n",
       "      <td>1.427322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.868524</td>\n",
       "      <td>1.566201</td>\n",
       "      <td>1.889605</td>\n",
       "      <td>-1.273761</td>\n",
       "      <td>-1.006278</td>\n",
       "      <td>1.873001</td>\n",
       "      <td>0.477862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.651825</td>\n",
       "      <td>1.319199</td>\n",
       "      <td>-0.022459</td>\n",
       "      <td>-1.209709</td>\n",
       "      <td>-1.430692</td>\n",
       "      <td>1.078345</td>\n",
       "      <td>2.812442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>-6.414403</td>\n",
       "      <td>0.723565</td>\n",
       "      <td>1.134953</td>\n",
       "      <td>2.952763</td>\n",
       "      <td>0.297928</td>\n",
       "      <td>-0.156946</td>\n",
       "      <td>2.398091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.851143</td>\n",
       "      <td>-2.217875</td>\n",
       "      <td>-2.812175</td>\n",
       "      <td>0.489249</td>\n",
       "      <td>-1.323410</td>\n",
       "      <td>-2.316883</td>\n",
       "      <td>2.113136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>1.422722</td>\n",
       "      <td>-1.907665</td>\n",
       "      <td>-2.532364</td>\n",
       "      <td>0.964976</td>\n",
       "      <td>-0.562375</td>\n",
       "      <td>-1.834765</td>\n",
       "      <td>0.697361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>-2.131904</td>\n",
       "      <td>-2.742600</td>\n",
       "      <td>-1.008029</td>\n",
       "      <td>2.126946</td>\n",
       "      <td>-0.802632</td>\n",
       "      <td>-3.580266</td>\n",
       "      <td>0.423569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>-2.660879</td>\n",
       "      <td>-2.044666</td>\n",
       "      <td>0.159026</td>\n",
       "      <td>1.499706</td>\n",
       "      <td>-1.581856</td>\n",
       "      <td>-1.605859</td>\n",
       "      <td>1.435644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Size    Weight  Sweetness  Softness  HarvestTime  Ripeness   Acidity\n",
       "0    -1.924968  0.468078   3.077832 -1.472177     0.294799  2.435570  0.271290\n",
       "1    -2.409751  0.486870   0.346921 -2.495099    -0.892213  2.067549  0.307325\n",
       "2    -0.357607  1.483176   1.568452 -2.645145    -0.647267  3.090643  1.427322\n",
       "3    -0.868524  1.566201   1.889605 -1.273761    -1.006278  1.873001  0.477862\n",
       "4     0.651825  1.319199  -0.022459 -1.209709    -1.430692  1.078345  2.812442\n",
       "...        ...       ...        ...       ...          ...       ...       ...\n",
       "7995 -6.414403  0.723565   1.134953  2.952763     0.297928 -0.156946  2.398091\n",
       "7996  0.851143 -2.217875  -2.812175  0.489249    -1.323410 -2.316883  2.113136\n",
       "7997  1.422722 -1.907665  -2.532364  0.964976    -0.562375 -1.834765  0.697361\n",
       "7998 -2.131904 -2.742600  -1.008029  2.126946    -0.802632 -3.580266  0.423569\n",
       "7999 -2.660879 -2.044666   0.159026  1.499706    -1.581856 -1.605859  1.435644\n",
       "\n",
       "[8000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# MinMaxScaler를 사용하여 데이터프레임의 값을 -1에서 1 사이의 값으로 변환\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "normalized_X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Softness</th>\n",
       "      <th>HarvestTime</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.239382</td>\n",
       "      <td>0.253494</td>\n",
       "      <td>0.361423</td>\n",
       "      <td>-0.278049</td>\n",
       "      <td>0.134624</td>\n",
       "      <td>0.343866</td>\n",
       "      <td>0.086832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.300098</td>\n",
       "      <td>0.256186</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>-0.412636</td>\n",
       "      <td>-0.036622</td>\n",
       "      <td>0.293700</td>\n",
       "      <td>0.091440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.043080</td>\n",
       "      <td>0.398896</td>\n",
       "      <td>0.145387</td>\n",
       "      <td>-0.432378</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>0.433160</td>\n",
       "      <td>0.234675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.107069</td>\n",
       "      <td>0.410788</td>\n",
       "      <td>0.191353</td>\n",
       "      <td>-0.251943</td>\n",
       "      <td>-0.053077</td>\n",
       "      <td>0.267181</td>\n",
       "      <td>0.113250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083345</td>\n",
       "      <td>0.375408</td>\n",
       "      <td>-0.082319</td>\n",
       "      <td>-0.243516</td>\n",
       "      <td>-0.114306</td>\n",
       "      <td>0.158859</td>\n",
       "      <td>0.411816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>-0.801655</td>\n",
       "      <td>0.290090</td>\n",
       "      <td>0.083341</td>\n",
       "      <td>0.304146</td>\n",
       "      <td>0.135075</td>\n",
       "      <td>-0.009526</td>\n",
       "      <td>0.358825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.108308</td>\n",
       "      <td>-0.131238</td>\n",
       "      <td>-0.481608</td>\n",
       "      <td>-0.019982</td>\n",
       "      <td>-0.098829</td>\n",
       "      <td>-0.303952</td>\n",
       "      <td>0.322383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.179895</td>\n",
       "      <td>-0.086804</td>\n",
       "      <td>-0.441559</td>\n",
       "      <td>0.042611</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>-0.238234</td>\n",
       "      <td>0.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>-0.265300</td>\n",
       "      <td>-0.206399</td>\n",
       "      <td>-0.223382</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>-0.023698</td>\n",
       "      <td>-0.476167</td>\n",
       "      <td>0.106306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>-0.331550</td>\n",
       "      <td>-0.106428</td>\n",
       "      <td>-0.056343</td>\n",
       "      <td>0.112966</td>\n",
       "      <td>-0.136114</td>\n",
       "      <td>-0.207031</td>\n",
       "      <td>0.235739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Size    Weight  Sweetness  Softness  HarvestTime  Ripeness   Acidity\n",
       "0    -0.239382  0.253494   0.361423 -0.278049     0.134624  0.343866  0.086832\n",
       "1    -0.300098  0.256186  -0.029450 -0.412636    -0.036622  0.293700  0.091440\n",
       "2    -0.043080  0.398896   0.145387 -0.432378    -0.001284  0.433160  0.234675\n",
       "3    -0.107069  0.410788   0.191353 -0.251943    -0.053077  0.267181  0.113250\n",
       "4     0.083345  0.375408  -0.082319 -0.243516    -0.114306  0.158859  0.411816\n",
       "...        ...       ...        ...       ...          ...       ...       ...\n",
       "7995 -0.801655  0.290090   0.083341  0.304146     0.135075 -0.009526  0.358825\n",
       "7996  0.108308 -0.131238  -0.481608 -0.019982    -0.098829 -0.303952  0.322383\n",
       "7997  0.179895 -0.086804  -0.441559  0.042611     0.010963 -0.238234  0.141321\n",
       "7998 -0.265300 -0.206399  -0.223382  0.195492    -0.023698 -0.476167  0.106306\n",
       "7999 -0.331550 -0.106428  -0.056343  0.112966    -0.136114 -0.207031  0.235739\n",
       "\n",
       "[8000 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X.to_pickle('xTrain_normalized.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
